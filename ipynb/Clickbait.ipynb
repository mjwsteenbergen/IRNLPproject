{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, Normalizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline #make_pipeline, make_union\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer #nltk.download('vader_lexicon')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# \n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_instances = pd.read_json(\"../fulldata/instances.jsonl\", lines=True, encoding='utf-8');\n",
    "df_truth = pd.read_json(\"../fulldata/truth.jsonl\", lines=True, encoding='utf-8'); \n",
    "# df_instances = pd.read_json(\"../data/instances.jsonl\", lines=True, encoding='utf-8');\n",
    "# df_truth = pd.read_json(\"../data/truth.jsonl\", lines=True, encoding='utf-8'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_instances[df_instances[\"targetTitle\"].str.contains(\"’\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possibleTruthClasses = ['no-clickbait', 'clickbait']\n",
    "\n",
    "sampler = RandomUnderSampler()\n",
    "merged = pd.merge(df_instances, df_truth, on='id')\n",
    "merged[\"truthClassN\"] = list(map(possibleTruthClasses.index, merged[\"truthClass\"]))\n",
    "\n",
    "# Display first 5 rows\n",
    "# display(merged.head())\n",
    "\n",
    "# Resample to get equal distribution.\n",
    "sampled_X, sampled_y = sampler.fit_resample(merged, merged[\"truthClassN\"])\n",
    "sampled_X = pd.DataFrame(sampled_X, columns=merged.columns)\n",
    "\n",
    "# Show distribution of classes\n",
    "display(sampled_X.groupby('truthClass').count()[[\"id\"]])\n",
    "\n",
    "# Remove labels to avoid cheating\n",
    "del sampled_X[\"truthClass\"]\n",
    "del sampled_X[\"truthClassN\"]\n",
    "del sampled_X[\"truthJudgments\"]\n",
    "del sampled_X[\"truthMean\"]\n",
    "del sampled_X[\"truthMedian\"]\n",
    "del sampled_X[\"truthMode\"]\n",
    "\n",
    "display(sampled_X.head())\n",
    "display(sampled_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sampled_X, sampled_y)\n",
    "display(X_train.head())\n",
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_number_regex = r\"[0-9]+\"\n",
    "is_word_regex = r\"[A-Za-z].*\"\n",
    "is_capital_word_regex = r\"[A-Z].*\"\n",
    "is_capital_letter_regex = r\"[A-Z]\" \n",
    "is_encoding_quot = r\"â€˜\"\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "sentimentAnalyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def cleanString(strin):\n",
    "    return strin#re.sub(is_encoding_quot, \"'\", strin)\n",
    "\n",
    "# def cleanString(strin):\n",
    "#     return re.sub(is_encoding_quot, \"'\", strin)\n",
    "\n",
    "def extract_features(df):\n",
    "    def extract(df):\n",
    "        result = dict()\n",
    "        #extract_from_title(df[1]['targetTitle'], result)\n",
    "        #extract_from_article(df[1]['targetParagraphs'], result)\n",
    "        extract_from_image(df[1]['postMedia'], result)\n",
    "        extract_from_post(df[1]['postText'], result)\n",
    "        return result\n",
    "        \n",
    "    def extract_from_title(title, result):\n",
    "        tiny = title.strip().lower()\n",
    "        title_words = nltk.word_tokenize(tiny)\n",
    "        title_words_p = nltk.word_tokenize(title.strip())\n",
    "        #title_words_stem_pos_repl = [(re.sub(is_number_regex, \"[n]\", \n",
    "        #                                         stemmer.stem(\n",
    "        #                                             word.lower())), tag) \n",
    "        #                             for (word, tag) in nltk.pos_tag(title_words_p)]\n",
    "        #title_words_stem = title_words\n",
    "        title_words_stem = [stemmer.stem(word) for word in title_words]\n",
    "        title_words_number_repl = [re.sub(is_number_regex, \"[n]\", word) for word in title_words_stem]\n",
    "        \n",
    "        #pos_title_word_count = Counter(title_words_stem_pos_repl)\n",
    "        #result.update({'pos_word_in_title[{}]'.format(word): 1 for word, amount in pos_title_word_count.items()})\n",
    "        \n",
    "        title_word_count = Counter(title_words_number_repl)\n",
    "        result.update({'word_in_title[{}]'.format(word): amount for word, amount in title_word_count.items()})\n",
    "        \n",
    "        n_words = sum(1 for word in title_words_p if re.match(is_word_regex, word))\n",
    "        n_capital_words = sum(1 for word in title_words_p if re.match(is_capital_word_regex, word))\n",
    "        result['title_capital_vs_non_words_ratio'] = 0 if n_words == 0 else n_capital_words/n_words\n",
    "        #pos_tag_count = Counter(tag for (word, tag) in nltk.pos_tag(title_words))\n",
    "        #pos_tag_count = Counter(tag for (word, tag) in nltk.pos_tag(title_words_p))\n",
    "        #result['title_length'] = len(title)\n",
    "        #result['simple_title_words'] = len(title_words)\n",
    "        #num_title_words_split = len(title.split(' '))\n",
    "        #result['title_words'] = len()\n",
    "        #result['title_question_marks'] = 0 if title.find('?') == -1 else 1\n",
    "        #result.update({'pos_tag[{}]'.format(tag): count for tag, count in pos_tag_count.items()})\n",
    "        #result['title_average_word_length'] = len(title) / num_title_words_split\n",
    "        \n",
    "        #twrr_bigram_count = Counter(nltk.bigrams(title_words_number_repl))\n",
    "        #result.update({'title_bigram[{}]'.format(bigram): count for bigram, count in twrr_bigram_count.items()})\n",
    "        \n",
    "        #sentiment = sentimentAnalyzer.polarity_scores(title)\n",
    "        #result['title_sent_neg'] = sentiment[\"neg\"]\n",
    "        #result['title_sent_pos'] = sentiment[\"pos\"]\n",
    "        #result['title_sent_neu'] = sentiment[\"neu\"]\n",
    "        return result\n",
    "    def extract_from_article(paragraphs, result):\n",
    "#         tiny = title.strip().lower()\n",
    "#         title_words = nltk.word_tokenize(tiny)\n",
    "        result['number_of_paragraphs'] = len(paragraphs)\n",
    "        entireArticle = ''.join(paragraphs)\n",
    "        result['article_length'] = len(entireArticle)\n",
    "        result['article_words'] = len(entireArticle.split(' '))\n",
    "        result['article_average_word_length'] = len(entireArticle) / len(entireArticle.split(' '))\n",
    "    \n",
    "        return result\n",
    "    def extract_from_image(postMedia, result):\n",
    "#         tiny = title.strip().lower()\n",
    "#         title_words = nltk.word_tokenize(tiny)\n",
    "        result['has_image'] = 1 if len(postMedia) > 0 else 0\n",
    "    \n",
    "        return result\n",
    "    def extract_from_post(lstPostText, result):\n",
    "        fullPostText = '\\n'.join(lstPostText)\n",
    "        # Use casual tokenizer as this is targeted at Tweet-like data.\n",
    "        # Normal tokenizer is unlikely to work well in this case.\n",
    "        tokenizedFullPostText = [re.sub(is_number_regex, \"[n]\", \n",
    "                                                 stemmer.stem(\n",
    "                                                     word.lower())) \n",
    "                                 for word in casual_tokenize(fullPostText)]\n",
    "        \n",
    "        #tokenizedNSPostText   = [re.sub(is_number_regex, \"[n]\", \n",
    "        #                                         stemmer.stem(\n",
    "        #                                             word.lower())) \n",
    "        #                         for word in casual_tokenize(fullPostText)\n",
    "        #                         if word.lower() not in eng_stopwords]\n",
    "        #                        \n",
    "        \n",
    "        # Maybe TODO: Manipulate Emoji, Remove weirder tokens ( -> :-) )\n",
    "        post_word_count = Counter(tokenizedFullPostText)\n",
    "        result.update({'word_in_post[{}]'.format(word): amount for word, amount in post_word_count.items()})\n",
    "        \n",
    "        result[\"post_word_count\"] = len(tokenizedFullPostText)\n",
    "        result[\"post_word_count_low\"] = len(tokenizedFullPostText) < 5\n",
    "        result[\"post_word_count_high\"] = len(tokenizedFullPostText) < 20\n",
    "        \n",
    "        post_bigram_count = Counter(nltk.bigrams(tokenizedFullPostText))\n",
    "        result.update({'bigram_in_post[{}]'.format(word): amount for word, amount in post_bigram_count.items()})\n",
    "        \n",
    "        # Similarily, POS tagger likely won't work well.\n",
    "        #tokenizedFullPostTextTagged = [(re.sub(is_number_regex, \"[n]\", \n",
    "        #                                         stemmer.stem(\n",
    "        #                                             word.lower())), tag)\n",
    "        #                         for (word, tag) in nltk.pos_tag(casual_tokenize(fullPostText))]\n",
    "        \n",
    "        #post_word_count = Counter(tokenizedFullPostTextTagged)\n",
    "        #result.update({'word_in_post[{}]'.format(word): amount for word, amount in post_word_count.items()})\n",
    "        #post_bigram_count = Counter(nltk.bigrams(tokenizedFullPostTextTagged))\n",
    "        #result.update({'bigram_in_post[{}]'.format(word): amount for word, amount in post_bigram_count.items()})\n",
    "        \n",
    "        \n",
    "        result['post_num_hashtags'] = fullPostText.count(\"#\")\n",
    "        result['post_num_usertags'] = fullPostText.count(\"@\")\n",
    "        result['post_capitals_ratio'] = (len(re.findall(is_capital_letter_regex, fullPostText))+1)/(len(fullPostText) + 1)\n",
    "        \n",
    "        sentiment = sentimentAnalyzer.polarity_scores(fullPostText)\n",
    "        result['post_sent_neg'] = sentiment[\"neg\"]\n",
    "        result['post_sent_pos'] = sentiment[\"pos\"]\n",
    "        result['post_sent_neu'] = sentiment[\"neu\"]\n",
    "        pass\n",
    "    \n",
    "    return map(extract, df.iterrows())\n",
    "\n",
    "# def extract_features_titles(df):\n",
    "#     def extract_from_title(title):\n",
    "#         result = dict()\n",
    "#         tiny = title.strip().lower()\n",
    "#         title_words = nltk.word_tokenize(tiny)\n",
    "#         title_words_stem = [stemmer.stem(word) for word in title_words]\n",
    "#         title_words_number_repl = [re.sub(is_number_regex, \"[n]\", word) for word in title_words_stem]\n",
    "#         twrr_bigram_count = Counter(nltk.bigrams(title_words_number_repl))\n",
    "#         result['title_word_count'] = sum(1 for word in title_words if re.match(is_word_regex, word))\n",
    "#         result['title_token_count'] = len(title_words)\n",
    "#         pos_tag_count = Counter(tag for (word, tag) in nltk.pos_tag(title_words))\n",
    "#         result.update({'pos_tag[{}]'.format(tag): count for tag, count in pos_tag_count.items()})\n",
    "# #         result.update({'title_bigram[{}]'.format(bigram): count for bigram, count in twrr_bigram_count.items()})\n",
    "#         return result\n",
    "#     return map(extract_from_title, df['targetTitle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(extract_features_titles(df_instances.iloc[:5]['targetTitle']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickbaitClassifierNBA = Pipeline([\n",
    "    ('feature_extraction', FunctionTransformer(extract_features, validate=False)),\n",
    "    ('encoder', DictVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "clickbaitClassifierTree = Pipeline([\n",
    "    ('feature_extraction', FunctionTransformer(extract_features, validate=False)),\n",
    "    ('encoder', DictVectorizer()),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "clickbaitClassifierXGB = Pipeline([\n",
    "    ('feature_extraction', FunctionTransformer(extract_features, validate=False)),\n",
    "    ('encoder', DictVectorizer()),\n",
    "    ('classifier', XGBClassifier())\n",
    "])\n",
    "\n",
    "clickbaitClassifierSVC = Pipeline([\n",
    "    ('feature_extraction', FunctionTransformer(extract_features, validate=False)),\n",
    "    ('encoder', DictVectorizer()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('classifier', LinearSVC(max_iter=4000))\n",
    "]) \n",
    "\n",
    "clickbaitClassifierMaxEnt = Pipeline([\n",
    "    ('feature_extraction', FunctionTransformer(extract_features, validate=False)),\n",
    "    ('encoder', DictVectorizer()),\n",
    "    ('normalizer', Normalizer()),\n",
    "    ('classifier', LogisticRegression(multi_class='multinomial', solver='lbfgs'))\n",
    "]) \n",
    "\n",
    "\n",
    "dummyClassifier = Pipeline([\n",
    "    ('feature_extraction', FunctionTransformer(extract_features, validate=False)),\n",
    "    ('encoder', DictVectorizer()),\n",
    "    ('classifier', DummyClassifier(strategy=\"most_frequent\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clickbaitClassifierNBA.fit(X_train, y_train);\n",
    "clickbaitClassifierTree.fit(X_train, y_train);\n",
    "clickbaitClassifierSVC.fit(X_train, y_train);\n",
    "clickbaitClassifierMaxEnt.fit(X_train, y_train);\n",
    "#clickbaitClassifierXGB.fit(X_train, y_train);\n",
    "dummyClassifier.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tree = clickbaitClassifierTree.predict(X_test)\n",
    "pred_nb = clickbaitClassifierNBA.predict(X_test)\n",
    "pred_svc = clickbaitClassifierSVC.predict(X_test)\n",
    "pred_maxent = clickbaitClassifierMaxEnt.predict(X_test)\n",
    "#pred_xgb = clickbaitClassifierXGB.predict(X_test)\n",
    "pred_dummy = dummyClassifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = [pred_tree, pred_nb, pred_svc, pred_xgb, pred_dummy]\n",
    "#preds = [pred_tree, pred_nb, pred_svc, pred_dummy]\n",
    "preds = [pred_tree, pred_nb, pred_maxent, pred_svc, pred_dummy]\n",
    "#classifiers = [\"DecisionTree\", \"NaiveBayes\", \"SVC\", \"XGBoost\", \"Dummy\"]\n",
    "#classifiers = [\"DecisionTree\", \"NaiveBayes\", \"SVC\", \"Dummy\"]\n",
    "classifiers = [\"DecisionTree\", \"NaiveBayes\", \"MaxEnt\", \"SVC\", \"Dummy\"]\n",
    "\n",
    "truthmap = y_test\n",
    "predsmap = preds\n",
    "#truthmap = [['clickbait', 'no-clickbait'].index(item) for item in y_test]\n",
    "#predsmap = [[['clickbait', 'no-clickbait'].index(item) for item in pred ] for pred in preds]\n",
    "\n",
    "precisions = [precision_score(truthmap, pred) for pred in predsmap]\n",
    "recalls = [recall_score(truthmap, pred) for pred in predsmap]\n",
    "accuracies = [accuracy_score(truthmap, pred) for pred in predsmap]\n",
    "cfm = [confusion_matrix(truthmap, pred) for pred in predsmap]\n",
    "\n",
    "pd.DataFrame({\"Classifier\": classifiers, \n",
    "               \"Accuracy\": accuracies,\n",
    "               \"Precision\": precisions,\n",
    "               \"Recall\": recalls,\n",
    "               \"CFM\": cfm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools.\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "classifiersPipelines = [clickbaitClassifierTree, clickbaitClassifierNBA, clickbaitClassifierMaxEnt, clickbaitClassifierSVC, dummyClassifier]\n",
    "classifiersNames = [\"DecisionTree\", \"NaiveBayes\", \"MaxEnt\", \"SVC\", \"Dummy\"]\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score)\n",
    "}\n",
    "\n",
    "def cross_validate_do(name, classifier):\n",
    "    result = cross_validate(classifier, sampled_X, sampled_y, scoring=scoring,\n",
    "                           cv=StratifiedKFold(n_splits=5, random_state=0));\n",
    "    result['name'] = name\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [cross_validate_do(name, classifier) \n",
    "           for (name, classifier) in zip(classifiersNames, classifiersPipelines)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "fields = ['fit_time', 'score_time', \n",
    "          'test_accuracy', 'test_precision', 'test_recall', \n",
    "          'train_accuracy', 'train_precision', 'train_recall']\n",
    "\n",
    "df_results[fields] = df_results[fields].apply(lambda l: l.map(np.median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = clickbaitClassifierTree.named_steps['classifier']\n",
    "dv = clickbaitClassifierTree.named_steps['encoder']\n",
    "#tr = clickbaitClassifierXGB.named_steps['classifier']\n",
    "#dv = clickbaitClassifierXGB.named_steps['encoder']\n",
    "\n",
    "dfFeatureImportance = pd.DataFrame(list(zip(dv.feature_names_, tr.feature_importances_)))\n",
    "dfOrdered = dfFeatureImportance.sort_values(1, ascending=False)\n",
    "display(dfOrdered[dfOrdered[1] > 0.00001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = clickbaitClassifierMaxEnt.named_steps['classifier']\n",
    "dv = clickbaitClassifierMaxEnt.named_steps['encoder']\n",
    "\n",
    "dfFeatureImportance = pd.DataFrame({'features': dv.feature_names_, 'coef': me.coef_.reshape(me.coef_.shape[1])})\n",
    "dfOrdered = dfFeatureImportance.sort_values('coef', ascending=False)\n",
    "dfOrderedAndFiltered = dfOrdered[dfOrdered['coef'].abs() > 0.5]\n",
    "display(dfOrderedAndFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(X_train.iloc[4]['targetTitle'])\n",
    "#display(cleanString(X_train.iloc[4]['targetTitle']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Digraph\n",
    "\n",
    "feature_regex = r\"X\\[([0-9]+)\\]\"\n",
    "value_regex = r\"value \\= \\[([0-9]+), ([0-9]+)\\]\"\n",
    "\n",
    "features_lst = dv.feature_names_\n",
    "\n",
    "ttab = str.maketrans({\n",
    "        #'\\'': \"\",\n",
    "        #'[' : \"\",\n",
    "        #']' : \"\",\n",
    "        #'(' : \"\",\n",
    "        #')' : \"\",\n",
    "        #' ' : \"\",\n",
    "        #',' : \"\",\n",
    "        #'_' : \"\",\n",
    "        #'$' : \"\",\n",
    "        '\"' : \"\\\\\\\"\"\n",
    "    })\n",
    "\n",
    "def replace_with_names(line):\n",
    "    def repl_feature(match):\n",
    "        a = \"\\'{}\\'\".format(features_lst[int(match.group(1))].translate(ttab))\n",
    "        #print(a)\n",
    "        return a\n",
    "    def repl_value(match):\n",
    "        a = \"Clickbait? No:{}, Yes:{}\".format(match.group(1),match.group(2))\n",
    "        #print(a)\n",
    "        return a\n",
    "    linerxr = re.sub(feature_regex, repl_feature, line)\n",
    "    linerxr = re.sub(value_regex, repl_value, linerxr)\n",
    "    return linerxr\n",
    "\n",
    "dotf = [replace_with_names(line) for line in export_graphviz(tr).split('\\n')[1:-1]]\n",
    "\n",
    "Digraph(body=dotf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pred_maxent\n",
    "predictor = clickbaitClassifierMaxEnt\n",
    "\n",
    "old_colwidth = pd.options.display.max_colwidth\n",
    "pd.options.display.max_colwidth = 200\n",
    "Xtst = X_test.copy()\n",
    "Xtst[\"predicted\"] = predicted\n",
    "tocmp = pd.merge(Xtst[[pred_i != corr_i for (pred_i, corr_i) in zip(predicted, y_test)]], df_truth, on=\"id\")\n",
    "proba = np.around(predictor.predict_proba(tocmp), 2)\n",
    "tocmp[\"prob_not_clickbait\"] = proba[:, 0]\n",
    "tocmp[\"prob_clickbait\"] = proba[:, 1]\n",
    "tocmpsel = tocmp[[\"id\", \"predicted\", \"prob_not_clickbait\", \"prob_clickbait\", \"truthClass\", \"targetTitle\", \"postText\", \"truthMean\", \"truthMedian\", \"truthJudgments\"]] \n",
    "display(tocmpsel)\n",
    "pd.options.display.max_colwidth = old_colwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tocmpsel.truthMean.hist()\n",
    "plt.savefig(\"hist2x.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedc = merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = extract_features(mergedc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = mergedc.join(pd.SparseDataFrame.from_dict(list(feat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(extracted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doExtract(dc):\n",
    "    if isinstance(dc, float):\n",
    "        return 0\n",
    "    else:\n",
    "        return dc.get('has_image', 0)\n",
    "extracted['has_image'] = extracted[0].apply(doExtract)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted.groupby('truthClass')['has_image'].count(by='has_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gby = extracted.groupby(['truthClass', 'has_image'])['has_image'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(X_test, df_truth, on=\"id\").truthMean.hist()\n",
    "plt.savefig(\"testhist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
